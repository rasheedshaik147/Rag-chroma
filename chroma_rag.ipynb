{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7caf98a7-b261-487a-9172-28dbcb9f7271",
   "metadata": {},
   "source": [
    "# Setting environment parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bf488-9023-458b-a0f1-ab299185ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1a7756-c07a-4ac9-8b18-6f438af5ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "CHROMA_PATH = \".\\chroma5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318f718-32fa-40f3-85a5-f84e54b58d4b",
   "metadata": {},
   "source": [
    "# load data into Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8d2dd-46b2-427b-93f1-c2883a29ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings()\n",
    "loaders = PyPDFLoader(\"C:\\\\Users\\\\JANARDHAN\\\\Documents\\\\Janardhan\\\\12Nov2024\\\\data_files\\\\Bhagavad-gita-Swami-BG-Narasingha.pdf\")\n",
    "\n",
    "documents = loaders.load()\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "db.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982711d9-4188-4efa-b580-41a80d620eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d386f13-d08b-4a1e-b6c1-9b4d696fceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61dd0ef-48dd-41ef-91b3-a25c3bc31886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "  \n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  # if len(results) == 0 or results[0][1] < 0.7:\n",
    "  #   print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    " \n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36979142-7e21-4ece-9af5-294ce37dc39a",
   "metadata": {},
   "source": [
    "# Ask Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf36209-00b1-4b11-a6db-64d25346e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JANARDHAN\\AppData\\Local\\Temp\\ipykernel_7436\\3764950876.py:34: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_text = model.predict(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krishna told Arjuna about the importance of fulfilling his dharma as a warrior and the impermanence of life. He also spoke about the concept of the self and the importance of detachment from the material world.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"what krishna told to Arjuna in chapter 2\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7cf06a-57fb-4923-a4d8-d805c0e1585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kurukshetra is a place or location.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"What is kurukshetra?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863b1eec-3e98-4099-916f-90ef9e2f96cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arjuna is a character from the Indian epic Mahabharata.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"Who is Arjuna?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567dfbeb-df36-417b-9a8b-bc3e469d84ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arjuna is popular for his role as a warrior prince in the Indian epic, the Mahabharata.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"FOr which Arjuna is popular for?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68276242-ba5f-4f41-8534-34e2d93ebc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arjuna is popular for his skill in archery.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"FOr which skill Arjuna is popular for?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13d139c-7039-484a-a257-64af45119f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arjuna, Bhima, Yudhishthira, Nakula, and Sahadeva\n"
     ]
    }
   ],
   "source": [
    "query_text=\"Provide me names of Pandavas?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf3e6f-cae3-4d81-b614-6256b6ae3a5e",
   "metadata": {},
   "source": [
    "# 1. get the embeddings for the query\n",
    "# 2. get the context from the chroma related to embeddings\n",
    "# 3. formulate the context based on query\n",
    "# 4. Ask the llm with the  context and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9294f7a-2c40-42ad-b550-8d692ad74d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Various yogas mentioned in the Bhagavadgita include Karma Yoga (the path of selfless action), Bhakti Yoga (the path of devotion), Jnana Yoga (the path of knowledge), and Dhyana Yoga (the path of meditation).\n"
     ]
    }
   ],
   "source": [
    "query_text=\"what are various yogas as mentioned in Bhagavadgita\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17eb2ff-94d7-459e-a853-6336e9584a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
